\documentclass[conference]{IEEEtran}

\usepackage{cite}
\usepackage{xcolor}
\usepackage{hyperref}
\hypersetup{colorlinks=true,linkcolor=black,citecolor=blue,filecolor=black,urlcolor=blue}
\usepackage{graphicx}
\graphicspath{{figures/}}

\newcommand{\TG}[1]{\color{red}\textsc{From Tristan: }#1\color{black}}
\newcommand{\MD}[1]{\color{magenta}\textsc{From Tristan: }#1\color{black}}
\newcommand{\HL}[1]{\hl{#1}}

\title{A Detailed Analysis of Performance Bottlenecks in MRI Pre-Processing}

\author{Mathieu Dugr\'e, Tristan Glatard}

\begin{document}
\maketitle

\begin{abstract}
	% TODO
		
\end{abstract}

\section{Introduction}
Magnetic Resonance Imaging (MRI) is a standard tool used by neuroscientists to perform clinical diagnosis and for researchers to develop a better understanding of the brain. Three main MRI techniques exist: structural MRI (sMRI), functional MRI (fMRI), and diffusion MRI (dMRI). While other modalities such as EEG, CT, and PET exist, we focus on MRIs for their broad adoption and non-invasive property. However, MRI data analysis is challenging due to computationally expensive pre-processing and large output and intermediate data size.

Neuroscientists developed various toolboxes to tackle the challenging task of pre-processing MRI data. Among those, some openly available and commonly accepted emerged: AFNI~\cite{Cox1996-sl}, ANTs~\cite{Avants_undated-fu}, FreeSurfer~\cite{Fischl2012-bp}, FSL~\cite{Jenkinson2012-cq}, and SPM~\cite{Friston2007-ag}. While the previous pipelines focus on specific steps of MRI pre-processing, tools like fMRIPrep~\cite{Esteban2019-og} and DIPY~\cite{Garyfallidis2014-ve} combine various pipelines to produce a complete pre-processing workflow.

The MRI pre-processing of a subject can take several hours, preventing the clinical use where data analysis might be required in timely manner. The lengthy pre-processing hinders researchers with limited computational resources to perform research on large cohorts.

The first step to improve performance of an application is to understand its performance bottleneck. Following, we can focus our efforts on the performance critical components. For example, better algorithm designs or usage of hardware accelerator can reduce computation time. Compression techniques can lower data transfer time for output and intermediate data. At last, reduced precision arithmetic can lower computation time, memory footprint, and storage size. While these techniques can provide significant performance improvements, their implementation can require substantial effort. Therefore, it is critical to understand the performance bottleneck of MRI pre-processing pipelines to improve their performance.

To the best of our knowledge, there is no comprehensive study of the bottlenecks in MRI pre-processing. In this paper, we characterize computational and I/O cost of several commonly adopted MRI pre-processing pipelines. The results of our analysis serve as a reference for future efforts to optimize the MRI pre-processing workflow.

\section{Background}

\subsection{MRI Pre-Processing}
% Look at the benchamrked tool and the information needed to abstract those tools.
% Discussion of the pre-processing steps.
% Explain their computation and I/O requirements.

% sMRI


% fMRI


% dMRI


\subsection{Intel VTune profiler}
% Requirements for profiling the Neuroimaging field.
% Multi-language support
% Lightweight
% Info on function and module runtime

% VTune

% Challenges remaining
% Debug information when compiling, for valuable information
% Combining the results from multiple analysis. Different input data can 
% vary the analysis significantly. (due to application branching and convergence)



\section{Methods}
\subsection{Infrastructure}
% TODO

\subsection{Dataset}
% TODO
% !!! TBD !!!
% size
% distribution: age, sex, race?, etc.
% Look into **CoRR** (more representative for this project) and HPC datasets.
% Need to have quality, yet not prestine, data with subject info for at least age and sex.

\subsection{Pipelines}
% TODO 
% !!! TBD !!!
% Motivation for those pipelines:

% MRI modalities
% fMRIprep (full) + sub-pipelines (sMRI + fMRI)
% DIPY pipelines (dMRI)

% Use case from papers
% LivingPark pipelines (sMRI)

\subsection{Profiling}
% How we did the profiling.
% Code to repository
% Aggregation of the results from different subjects.


\section{Results}
% TODO
% 2-step approach:
% 1. Which pipeline constitute the long execution time in preprocessing?
% 2. For those, which functions take the most time to execute? (hotspot)

\subsection{Makespan}
% Identify which tools take the longest to execute.

% ###    FIGURE    ###
%  Bar chart with the total makespan of the pipeline execution (mean + std)
% ### END FIGURE ####
% This will let us decided which pipeline to investigate more.

\subsection{Hotspot}
% (1-2 pages)
% TopK (approx. 10) longest makepsan application. The rest can go in supplemental.
% ###    FIGURE    ###
% (Large pipeline)
% fMRIPrep
% sMRIPrep
% DIPY
% 
% (Pipeline components)
% FreeSurfer
% ANTs ??
% SPM DARTEL
% ### END FIGURE ####

% Supplementary figure for the sub-components of large pipelines.

\section{Discussion}
% TODO
% Principal Bottlenecks

% Limitation
% Can only perform profiling of open-source pipelines
% Or pipelines with debug-info.

% Opportunity for optimisation (future work)
% Reduced precision for: Compute or Compression

\section{Conclusion}
% TODO

\section*{Acknowledgement}
% TODO

\section*{Data Availability}
% TODO
The code to compile, profile, and execute the pipelines is publicly available at:

\href{https://github.com/mathdugre/neuro-bottleneck}{https://github.com/mathdugre/neuro-bottleneck}
% TODO Update URL to slashbin org, when created.

\section*{Conflict of Interests}
The authors report no conflict of interests.

\section*{Supplementary Figures}
% Pipelines' hotspot with bottomK makespan

\bibliographystyle{IEEEtran}
% \bibliography{IEEEabrv, paper}
\bibliography{paper}


\end{document}
