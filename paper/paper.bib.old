@article{Avants2011-ks,
  title    = {{A reproducible evaluation of ANTs similarity metric performance
              in brain image registration}},
  author   = {Avants, Brian B and Tustison, Nicholas J and Song, Gang and Cook,
              Philip A and Klein, Arno and Gee, James C},
  abstract = {The United States National Institutes of Health (NIH) commit
              significant support to open-source data and software resources in
              order to foment reproducibility in the biomedical imaging
              sciences. Here, we report and evaluate a recent product of this
              commitment: Advanced Neuroimaging Tools (ANTs), which is
              approaching its 2.0 release. The ANTs open source software
              library consists of a suite of state-of-the-art image
              registration, segmentation and template building tools for
              quantitative morphometric analysis. In this work, we use ANTs to
              quantify, for the first time, the impact of similarity metrics on
              the affine and deformable components of a template-based
              normalization study. We detail the ANTs implementation of three
              similarity metrics: squared intensity difference, a new and
              faster cross-correlation, and voxel-wise mutual information. We
              then use two-fold cross-validation to compare their performance
              on openly available, manually labeled, T1-weighted MRI brain
              image data of 40 subjects (UCLA's LPBA40 dataset). We report
              evaluation results on cortical and whole brain labels for both
              the affine and deformable components of the registration. Results
              indicate that the best ANTs methods are competitive with existing
              brain extraction results (Jaccard=0.958) and cortical labeling
              approaches. Mutual information affine mapping combined with
              cross-correlation diffeomorphic mapping gave the best cortical
              labeling results (Jaccard=0.669$\pm$0.022). Furthermore, our
              two-fold cross-validation allows us to quantify the similarity of
              templates derived from different subgroups. Our open code, data
              and evaluation scripts set performance benchmark parameters for
              this state-of-the-art toolkit. This is the first study to use a
              consistent transformation framework to provide a reproducible
              evaluation of the isolated effect of the similarity metric on
              optimal template construction and brain labeling.},
  journal  = {Neuroimage},
  volume   = 54,
  number   = 3,
  pages    = {2033--2044},
  month    = feb,
  year     = 2011,
  url      = {http://dx.doi.org/10.1016/j.neuroimage.2010.09.025},
  keywords = {Tool / Framework;Neuroimaging;My papers/mri-bottleneck},
  language = {en},
  issn     = {1053-8119, 1095-9572},
  pmid     = {20851191},
  doi      = {10.1016/j.neuroimage.2010.09.025},
  pmc      = {PMC3065962}
}
